{"cells":[{"cell_type":"markdown","metadata":{"id":"XwRnOU3TTcSS"},"source":["# Install dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JxgDu46oTbj7","trusted":true},"outputs":[],"source":["!pip install -q TTS\n","!sudo apt-get -y install espeak-ng"]},{"cell_type":"markdown","metadata":{"id":"D_PWn1BnUYXr"},"source":["## Insert Dataset"]},{"cell_type":"markdown","metadata":{},"source":["You can use kaggle api to download dataset:\n","https://www.kaggle.com/datasets/magnoliasis/persian-tts-dataset-famale"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-12-23T13:21:19.931307Z","iopub.status.busy":"2022-12-23T13:21:19.930904Z","iopub.status.idle":"2022-12-23T13:21:20.876866Z","shell.execute_reply":"2022-12-23T13:21:20.875514Z","shell.execute_reply.started":"2022-12-23T13:21:19.931274Z"},"id":"UzjI324SYnSI","trusted":true},"outputs":[],"source":["!mkdir train_output"]},{"cell_type":"markdown","metadata":{},"source":["You should set your own dataset path in bellow cell like this:\n","\n","exp. : my dataset path is `/contents/persian-tts-dataset-famale` and these are files under folder:\n","```\n","/contents/persian-tts-dataset-famale\n","|-- wavs\n","|   |-- 1.wav\n","|   |-- 2.wav\n","|   |-- 3.wav\n","|   |-- ...\n","|\n","|\n","|-- metadata.csv\n","```\n","So this part of code should be (lines 26-28 in train_glowtts.py or bellow cell) like this:\n","```\n","dataset_config = BaseDatasetConfig(\n","    formatter=\"mozilla\", meta_file_train=\"metadata.csv\", path=\"/contents/persian-tts-dataset-famale\" \n",")\n","```\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2022-12-23T14:09:14.192412Z","iopub.status.busy":"2022-12-23T14:09:14.192050Z","iopub.status.idle":"2022-12-23T14:09:14.201899Z","shell.execute_reply":"2022-12-23T14:09:14.200714Z","shell.execute_reply.started":"2022-12-23T14:09:14.192382Z"},"id":"O3CyHQ3YTLUp","trusted":true},"outputs":[],"source":["code='''import os\n","\n","from trainer import Trainer, TrainerArgs\n","\n","from TTS.tts.configs.shared_configs import BaseDatasetConfig , CharactersConfig\n","from TTS.config.shared_configs import BaseAudioConfig\n","from TTS.tts.configs.vits_config import VitsConfig\n","from TTS.tts.datasets import load_tts_samples\n","from TTS.tts.models.vits import Vits, VitsAudioConfig\n","from TTS.tts.utils.text.tokenizer import TTSTokenizer\n","from TTS.utils.audio import AudioProcessor\n","from TTS.utils.downloaders import download_thorsten_de\n","\n","output_path = os.path.dirname(os.path.abspath(__file__))\n","dataset_config = BaseDatasetConfig(\n","    formatter=\"mozilla\", meta_file_train=\"metadata.csv\", path=\"/kaggle/input/persian-tts-dataset-famale\" \n",")\n","\n","\n","\n","audio_config = BaseAudioConfig(\n","    sample_rate=24000,\n","    do_trim_silence=True,\n","    resample=False,\n","    mel_fmin=0,\n","    mel_fmax=None \n",")\n","character_config=CharactersConfig(\n","  characters='ءابتثجحخدذرزسشصضطظعغفقلمنهويِپچژکگیآأؤإئًَُّ',\n","  punctuations='!(),-.:;? ̠،؛؟‌<>',\n","  phonemes='ˈˌːˑpbtdʈɖcɟkɡqɢʔɴŋɲɳnɱmʙrʀⱱɾɽɸβfvθðszʃʒʂʐçʝxɣχʁħʕhɦɬɮʋɹɻjɰlɭʎʟaegiouwyɪʊ̩æɑɔəɚɛɝɨ̃ʉʌʍ0123456789\"#$%*+/=ABCDEFGHIJKLMNOPRSTUVWXYZ[]^_{}',\n","  pad=\"<PAD>\",\n","  eos=\"<EOS>\",\n","  bos=\"<BOS>\",\n","  blank=\"<BLNK>\",\n","  characters_class=\"TTS.tts.utils.text.characters.IPAPhonemes\",\n","  )\n","config = VitsConfig(\n","    audio=audio_config,\n","    run_name=\"vits_fa_female\",\n","    batch_size=32,\n","    eval_batch_size=16,\n","    batch_group_size=5,\n","    num_loader_workers=0,\n","    num_eval_loader_workers=2,\n","    run_eval=True,\n","    test_delay_epochs=-1,\n","    epochs=1000,\n","    save_step=1000,\n","    text_cleaner=\"basic_cleaners\",\n","    use_phonemes=True,\n","    phoneme_language=\"fa\",\n","    characters=character_config,\n","    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n","    compute_input_seq_cache=True,\n","    print_step=25,\n","    print_eval=True,\n","    mixed_precision=False,\n","    test_sentences=[\n","        [\"سلطان محمود در زمستانی سخت به طلخک گفت که: با این جامه ی یک لا در این سرما چه می کنی \"],\n","        [\"مردی نزد بقالی آمد و گفت پیاز هم ده تا دهان بدان خو شبوی سازم.\"],\n","        [\"از مال خود پاره ای گوشت بستان و زیره بایی معطّر بساز\"],\n","        [\"یک بار هم از جهنم بگویید.\"],\n","        [\"یکی اسبی به عاریت خواست\"]\n","    ],\n","    output_path=output_path,\n","    datasets=[dataset_config],\n",")\n","\n","# INITIALIZE THE AUDIO PROCESSOR\n","# Audio processor is used for feature extraction and audio I/O.\n","# It mainly serves to the dataloader and the training loggers.\n","ap = AudioProcessor.init_from_config(config)\n","\n","# INITIALIZE THE TOKENIZER\n","# Tokenizer is used to convert text to sequences of token IDs.\n","# config is updated with the default characters if not defined in the config.\n","tokenizer, config = TTSTokenizer.init_from_config(config)\n","\n","# LOAD DATA SAMPLES\n","# Each sample is a list of ```[text, audio_file_path, speaker_name]```\n","# You can define your custom sample loader returning the list of samples.\n","# Or define your custom formatter and pass it to the `load_tts_samples`.\n","# Check `TTS.tts.datasets.load_tts_samples` for more details.\n","train_samples, eval_samples = load_tts_samples(\n","    dataset_config,\n","    eval_split=True,\n","    eval_split_max_size=config.eval_split_max_size,\n","    eval_split_size=config.eval_split_size,\n",")\n","\n","# init model\n","model = Vits(config, ap, tokenizer, speaker_manager=None)\n","\n","# init the trainer and 🚀\n","trainer = Trainer(\n","    TrainerArgs(),\n","    config,\n","    output_path,\n","    model=model,\n","    train_samples=train_samples,\n","    eval_samples=eval_samples,\n",")\n","trainer.fit()'''\n","f=open(\"train_output/train_vits.py\",\"w\",encoding=\"utf-8\")\n","\n","f.write(code)\n","\n","f.close()"]},{"cell_type":"markdown","metadata":{"id":"HiVwNfXHYEgD"},"source":["# Start training"]},{"cell_type":"markdown","metadata":{},"source":["For training on first time run this cell: "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!PYTORCH_CUDA_ALLOC_CONF=\"max_split_size_mb:512\" python \"train_output/train_vits.py\""]},{"cell_type":"markdown","metadata":{},"source":["to continue training run this cell: \n","- set your own `continue_path`"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!PYTORCH_CUDA_ALLOC_CONF=\"max_split_size_mb:512\" python \"train_output/train_vits.py\" --continue_path 'train_output/run-December-23-2022_02+09PM-0000000'"]},{"cell_type":"markdown","metadata":{},"source":["# finetuning"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!mkdir train_output/my_model"]},{"cell_type":"markdown","metadata":{},"source":["Download my last pretrained checkpoint and `config.json` :"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!wget \"https://huggingface.co/Kamtera/persian-tts-female-vits/resolve/main/checkpoint_48000.pth\" -O \"train_output/my_model/best_model.pth\"\n","!wget \"https://huggingface.co/Kamtera/persian-tts-female-vits/blob/main/config-2.json\" -O \"train_output/my_model/config.json\""]},{"cell_type":"markdown","metadata":{},"source":["You could use default settings in `config.json` or edit it with your own parameters."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python \"train_output/train_vits.py\" --restore_path \"train_output/my_model/best_model.pth\" "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"nbformat":4,"nbformat_minor":4}
